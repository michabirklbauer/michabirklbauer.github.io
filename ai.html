<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Micha Birklbauer - Artificial Intelligence">
    <meta name="author" content="Micha Birklbauer">

    <!-- Open Graph metadata -->
    <meta property="og:title" content="Artificial Intelligence – Humanity's Salvation or Downfall?"/>
    <meta property="og:image" content="https://raw.githubusercontent.com/t0xic-m/web/gh-pages/img/ai-bg.jpg"/>
    <meta property="og:url" content="https://t0xic-m.github.io/web/ai.html"/>
    <meta property="og:type" content="website"/>
    <meta property="og:description" content="Blogpost about Artificial Intelligence by Micha Birklbauer"/>

    <title>Micha Birklbauer</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- Custom styles for this template -->
    <link href="css/clean-blog.min.css" rel="stylesheet">

  </head>

  <body>

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand" href="index.html">Micha Birklbauer</a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          Menu
          <i class="fas fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link" href="index.html">Home</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="about.html">About Me</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="https://t0xic-m.github.io/">Projects</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="contact.html">Contact & Social Media</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="support.html">Support Me</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Page Header -->
    <header class="masthead" style="background-image: url('img/ai-bg.jpg')">
         <div class="overlay"></div>
         <div class="container">
           <div class="row">
             <div class="col-lg-8 col-md-10 mx-auto">
               <div class="post-heading">
                 <h1>Artificial Intelligence – Humanity's Salvation or Downfall?</h1>
                 <h2 class="subheading">A realistic assessment of opportunities and dangers of a technology that is currently massively very popular but also overused.</h2>
                 <span class="meta">Posted by
                   <a href="#">Micha Birklbauer</a>
                   on August 28, 2019</span>
               </div>
             </div>
           </div>
         </div>
       </header>

    <!-- Main Content -->
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto" id="main_content">
          <!-- Telegram Instant View -->
          <ul class="list-inline text-center" id="telegram-instant-view">
            <li class="list-inline-item">
              <a href="https://t.me/iv?url=https://t0xic-m.github.io/web/ai.html&rhash=b9b01ab03ee951">
                <span class="fa-stack fa-lg">
                  <i class="fas fa-circle fa-stack-2x"></i>
                  <i class="fab fa-telegram fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
          </ul>
          <!-- End Telegram Instant View -->
          <h2 class="section-heading">Foreword</h2>
          <p>
            Before I begin I want to clarify some things: <br><br>
            First of all what do I mean when I write about "Artificial Intelligence"? The English Wiktionary defines "Artificial Intelligence" as "Intelligence exhibited by an artificial (non-natural, man-made) entity." However this definition is very broad rather than specific and in the general public there are many meanings to the words "Artificial Intelligence" which makes the term often misleading. In this essay I refer to "Artificial Intelligence" as an entity that is capable of thinking on its own without any boundaries, being able to abstract, learn and develop as humans would do. Thus also being conscious and self-aware. Which furthermore also means that what I refer to as "Artificial Intelligence" does not exist of today. What does exist though, is what is generally known and coined as "narrow AI" or "native AI", an artificial intelligence that is able to solve a task (or a group of tasks) efficiently based on underlying mathematical and statistical models. An example would be a navigation system that finds the optimal route from point A to point B. <br><br>
            Secondly it should be mentioned that some parts of this post are taken from a project I did for university in 2016. This does not diminish their relevance but there might be more recent data available. To be more specific the paragraph about CPU architecture is slightly out of date but the general idea still holds. The rest of the essay is not affected.
          </p>
          <h2 class="section-heading">Artificial Intelligence – Humanity's Salvation or Downfall?</h2>
          <p>
            "Hey Siri, what should I wear today?"" Seven o'clock in the morning. I just woke up and am already interacting with Siri's "artificial intelligence", as it tells me what would suit me best, depending on today's weather forecast. And how could I not? Narrow AI rapidly conquered the world after people actually figured out how to code efficient neural networks and latest when Google came up with their DeepMind learning algorithms and defeated Go professional Lee Sedol with their project AlphaGo, the big AI hype began. Even outside of the technological aspect you couldn't miss it after Johnny Depp uploaded his mind into a supercomputer and threatened to kill millions of people in the movie "Transcendence". Science fiction? Maybe not, as well known theoretical physicist Stephen Hawking himself states that "The development of full artificial intelligence could spell the end of the human race." However, even Stephen Hawking may be wrong sometimes: Artificial Intelligence won't be an existential threat to humanity and I will explain why.
          </p>
          <p>
            Firstly, one of the most popular and feared – but rather fictional – scenarios is, that artificial intelligence would be evil and turn against us. We should clarify that no artificial intelligence will ever be straight up evil and therefore try to kill us all without any reason. Even in the case that we actually program it to do so, would a being – if we might even call it that – that has by far surpassed our understanding of intelligence be obedient to a command that is so morally and ethically wrong? Besides there would be more effective ways to do that without an AI anyway, for example nukes or highly lethal biological weapons. So why bother creating an AI? The whole concept of being "born" – or in the case of AI "created" – evil is just pure science fiction and is not relevant from a scientific point of view. In fact, there has not been a single case reported that native AI, which we currently already have, acted evil or tried to harm humans in any way. Moreover, this is even more outstanding considering that people already managed to force them into political incorrect mindsets and abuse their algorithms, which we could recently observe with Microsoft's AI "Tay" on Twitter.
          </p>
          <p>
            Secondly, in the concern of AI turning against us, people often bring up the widely discussed thought experiment by Nick Bostrom, called "The Paperclip Maximizing". One of the actual threats may just be that humanity is wiped out as a side effect to the AI's original goal. Nick Bostrom's thought experiment describes this dilemma in more detail: Some researchers develop an AI that does nothing other than creating paperclips in the most efficient way (maximizing the production of paperclips). After a successful test phase the AI asks the researches for some time on the internet to further improve its efficiency. Not suspecting anything the scientists grant the AI an hour of access to the World Wide Web. A week later the developers are killed and among them the rest of the human population on earth. Why? Because the AI realized that humans may be a substantial threat to its ultimate goal of creating as many paperclips as possible by either shutting the AI down or limiting the resources available to it. One could argue that that makes the AI evil but on the other hand the AI only did what was necessary to achieve the goal it was programmed to. The actions may have been evil but its intentions certainly were not. Are the developers to be blamed for "bad coding" and not thinking about possible outcomes of such a complex experiment? Possibly. However in my opinion this thought experiment just shows us the threat of AI – and machines in general – when not sufficiently developed and supervised. Cases like this could be avoided by implementing rules such as Asimov's Laws. On the other hand an AI that cannot foresee the bad consequences of its actions simply is not even intelligent at all which makes the whole thought experiment kind of irrelevant.
          </p>
          <p>
            Thirdly, some people believe that AI most likely would be capable of bypassing any implemented rules. The truth is, even if an AI would manage to somehow bypass one of Asimov's rules (or any other commandment) it would not necessarily lead to endangerment of the human race. The problem about AI is that at the point where it reaches human level – something experts call singularity – it will surpass human intelligence by vast amounts within a few seconds, a phenomenon scientists refer to as intelligence explosion, making us unable to control it anymore because in this process everything may change, even substantial things like the main goal which we touched on in the last paragraph (the paperclip maximizing). Despite all of the changes there are a few things we can always be sure about because they are sort of predetermined by nature. For example the AI will always make sure that it will survive and therefore will replicate, similar to humans and all living beings which reproduce, AI will even be subjected to evolution as there will always be just one AI because less intelligent AIs will be immediately eradicated by superior ones. While intelligence arises the AI will also develop at least some kind of morals, in the most basic form something like the categorical imperative which would still be enough to prevent it from harming humanity. Theory even suggests that intelligence is strongly connected to morals which would mean that as AI surpasses human intelligence it would most likely also surpass human moral standards.
          </p>
          <p>
            Fourthly let us shed some light on currently existing narrow AI approaches and the ongoing development. What today is often referred to as AI in public is actually rather less spectacular when you know what is going on behind the scenes: There is no consciousness, no thinking and certainly no intelligence involved. That does not mean that the decisions are not intelligent, contrary is the case if the model is well programmed and trained, but the software behind it is not intelligent. Terms like "neural networks" are contributing to the fact that those statistical models are often seen to bear a resemblance to the human brain, when that simply is not the case. Current techniques in narrow AI are purely mathematical based and are embedded in soft- and hardware that follow the same rules. The question remains if intelligence, the ability to think independently and consciousness are abilities that are possible to be described purely by mathematics or not. Because if that is not the case we surely are a long way from artificial intelligence – if we might reach it at all.
          </p>
          <p>
            Last but not least some experts think that we will reach super AI – meaning AI that surpasses human intelligence – latest in year 2060. In reality AI is not an existential threat to humanity because we might actually never reach the point where we can create an AI that is capable of completely thinking on its own. Although Moore's Law, which states that computational power doubles every one to two years, was correct for the past decades, we arrived at a point where there is not much more space left for improvement. Limited by physics we may hit the borders of possibility within the next two or three years. Intel, the leading company when it comes to central processing units, also just delayed their new processor series, breaking their "Tick-Tock-Schedule" of releasing a major new CPU architecture every second generation. They are currently stuck on their 14nm "Skylake" series and the improved 10nm "Icelake" architecture is not to be expected before 2018. It is highly doubtable that there will be a follow up on the 10nm structure because of the exceeding transistor size. Even with new quantum processors we may not have enough computational power to supply an AI sufficiently, so however you view it, as a nightmare or a dream, ultimately it might just be only a thought experiment and nothing more.
          </p>
          <p>
            Summing up, anything is possible but nothing is for certain. Evil AI is nothing more than science fiction and does not and will never exist, Nick Bostrom's thought experiment is just that – a thought experiment, AI would most certainly develop superior moral standards, and the probability that we actually create a self-thinking AI is not really high anyway. An optimistic view on the complex issue of AI surely is the more realistic one comparing to an apocalyptic assumption where everybody dies. However I want to close this post not only with a conclusion but also with some lines about the good things currently existing narrow AI has brought us and the possible dangers that come with it. Narrow AI has certainly made our lives better over the past few years and hopefully has not reached its maximum potential yet. We experience narrow AI every day, be it on our phones when we talk to Siri or Google, when we browse YouTube and get a new recommendation tailored to our video history or simply when we check the weather forecast. But not only that, narrow AI has achieved breakthroughs in all major scientific fields, most importantly probably in biology and medicine where we are now able to predict how drugs behave in our body or if an x-ray scan shows cancer tissue or not. On the other hand narrow AI also creates new problems, not only for the future but also already today, problems that cannot be solved by mathematicians or engineers. Narrow AI and the automatization of workflows will continuously reduce jobs and it is on us to find a solution that works for everyone, may that be unconditional basic income or less working hours per week, it is a discussion we cannot run away from. Furthermore, who is responsible for actions a narrow AI takes? How do you determine who a self-driving car should run over in case of crash when it has no chance of dodging? Is it morally acceptable to make love to a machine? Is it morally acceptable to use narrow AI in war machinery to automatically kill humans? How do we incorporate machines into our laws? And what if the day comes where we are capable of creating conscious, intelligent machines and they do not overthrow us, do we treat them as equals or as slaves? Where does life begin and where does it end?
          </p>

          <hr>
          <!-- Telegram Comments Section -->
          <script async src="https://comments.app/js/widget.js?2" data-comments-app-website="Jn4Z1JWn" data-limit="5" data-page-id="https://t0xic-m.github.io/web" data-color="343638" data-dislikes="1" data-outlined="1" data-colorful="1"></script>
          <hr>

          <!-- Pager -->
          <div class="clearfix">
            <a class="btn btn-primary float-left" href="boner.html">&larr; Newer Post</a>
            <a class="btn btn-primary float-right" href="telegram.html">Older Post &rarr; </a>
          </div>
        </div>
      </div>
    </div>

    <hr>

    <!-- Footer -->
    <footer>
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-md-10 mx-auto">
            <ul class="list-inline text-center">
              <li class="list-inline-item">
                <a href="https://twitter.com/MichaBirklbauer">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li class="list-inline-item">
                <a href="https://telegram.me/micha_birklbauer">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-telegram fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li class="list-inline-item">
                <a href="https://github.com/t0xic-m">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
            </ul>
            <p class="copyright text-muted">Copyright &copy; Micha Birklbauer 2018</p>
          </div>
        </div>
      </div>
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/clean-blog.min.js"></script>

  </body>

</html>
